---
title: "Lab 4: Direct Porting of Neotoma Data into R: APIs and _neotoma_"
Author: "Simon Goring, Quinn Asena, with modifications by Jack Williams"
date: "August 18, 2022"
format:
  html:
    code-fold: false
    toc: true
    link-external-newwindow: true
theme:
  light: flatly
  dark: darkly
---

# Before the lab

__Install packages:__

- `neotoma2`, `analogue`, and `rworldmap`. __??? all still necessary, rijoa replaced analogue?, rworldmap replaced by leaflet? ????__

:::{.callout-tip}
## Note:

To download the latest version of `neotoma2` you will need to download it from the source on GitHub.

```{r, eval=FALSE}

install.packages("devtools")
devtools::install_github('NeotomaDB/neotoma2')

```
:::

__Read:__

Goring, S., Dawson, A., Simpson, G., Ram, K., Graham, R. W., Grimm, E. C., and Williams, J. W. (2015) neotoma: A Programmatic Interface to the Neotoma Paleoecological Database. Open Quaternary 1:1-17.


# Introduction

This series of exercises is designed to give you hands-on practice in using APIs and the `neotoma2` R package (Goring et al, 2015), both for practical reasons and for insights into how open-data systems work. `neotoma2`’s primary purpose is to pass data from the Neotoma Paleoecology Database (Neotoma DB) into the R environment. Neotoma relies on Application Programming Interfaces ([APIs](https://en.wikipedia.org/wiki/API)) to communicate with the Neotoma Paleoecology Database, so we’ll begin with an introduction to APIs.

Note that the R components of this exercise are adapted from materials originally developed by Simon Goring, Jack Williams, and others for Neotoma training workshops at PalEON and elsewhere (e.g. [HTML](https://open.neotomadb.org/EPD_binder/simple_workflow.html) and GitHub) and are reproduced here under the [MIT](https://opensource.org/licenses/MIT) License.

## Goals

- Understand the flow of data through the Neotoma Paleoecology Database package, APIs, and neotoma package.

- Learn how to use the neotoma R package and key functions (e.g. `get_sites()`, `get_datasets()`, `get_downloads()`)

- Learn and develop code for single-site and multi-site data visualizations.

- Learn to prepare Neotoma data for passing to standard software such as analogue

## Resources

- [GitHub](https://github.com/NeotomaDB) repository for the `neotoma2` R package:

- [neotoma2 manual](https://neotoma-manual.readthedocs.io/en/latest/)

# Part 1: APIs


## APIs

The Neotoma Paleoecology Database is a relational database, hosted on servers at [Penn State’s Center for Environmental Informatics](https://sites.psu.edu/environmentalinformatics/). For security reasons, direct access to these servers is quite limited, and available only to a few Neotoma and CEI programmers.

__APIs__ offer public access points into Neotoma that anyone can use. Each API is basically a function: you provide the API with a set of operational parameters, and it returns a set of data or metadata. Each API hence is designed to support one particular task or set of tasks; it offers a narrow window into the larger Neotoma DB. [REST-ful APIs](https://en.wikipedia.org/wiki/Representational_state_transfer) follow a particular set of standards that allow them to be read by web browsers (i.e. within the HTTP protocol) and return data objects, typically in HTML, XML, JSON or other human- & machine-readable formats

The [__Neotoma APIs__](https://api.neotomadb.org/api-docs/) provide a series of functions for retrieving different kinds of data from Neotoma DB. Data objects are returned in [JSON](https://en.wikipedia.org/wiki/JSON) format. For this exercise, we strongly recommend adding an extension to your browser that formats the JSON output to make it easier to read, such as [JSONView](https://addons.mozilla.org/en-US/firefox/addon/jsonview/).

__The APIs for Neotoma are in transition right now, with version 1.0 the working version and versions 1.5 and 2.0 at the beta stage. The V1.5 and 2.0 APIs can be found here: https://api.neotomadb.org/api-docs/__

__Look through the lists of different APIs and find the one labled GET /v2.0/data/sites/{siteid}. Then, click on the Try It Out button at right, enter 666 into the site identifier box, and click Execute.__

__Then scroll down. You you should see some example code in curl format (ignore this) and as a URL. If you scroll down further, you’ll see the actual data return, in JSON format. JSON is a structured data format designed to be both human-readable and machine-readable. It looks like a nested series of lists__

__Let’s also try a V1.0 API. Put this right in the URL box in your browser:__

https://api.neotomadb.org/v1/data/sites?sitename=*devil*

__This should open a new web page in your browser with a returned JSON object. For this search, the JSON object should include 16 or more sites with the name ‘devil’ in them (note the use of asterisks as wildcards), including Devil’s Lake, WI. The opening line success = 1 means that the API ran successfully.__

__Note that it is possible for an API to run successfully but return no data! For example, try:__

api.neotomadb.org/v1/data/sites?sitename=devil

__Here, success = 1, but data=[], i.e. the API successfully reported back to you that no sites in Neotoma have the exact name of ‘devil’.__

__OK, now your turn:__
__Exercise Question 1 Use the sites API to retrieve site data for sites of interest. The sites API has a few different parameters, so try out options. In your homework exercise, provide at least two sites API calls with a comment line.__


# Part 2: Neotoma workflow

The `neotoma2` package provides a series of functions inside of R, each one of which calls one or more APIs. neotoma was primarily written by Simon Goring, with support from NSF-Geoinformatics and the ROpenSci project. 

__The structure of the Neotoma data model, as expressed through the API is roughly: “counts of a fossil taxa within download, download within dataset, dataset within site”. So a dataset contains information about a particular dataset from a given site. A site may have one or several associated datasets.__

The neotoma data structure is as follows (take note of plural/singular):

- sites: multiple locations (e.g., several lakes)

- site: a single location (e.g., a single lake)

- collection units: one or more sediment core samples from a site

- collection unit: a simgle core sample

- datasets: the number of datasets from a single collection unit (e.g., pollen is one dataset, diatoms may be another)

- dataset: an individual record (e.g., only the pollen data from a core)

- chronologies: age-depth models associated with a single core (there may be more than one chronology per core)

- chronology: a single chronology associated with a core sample

![`neotoma2` structure and associated functions](AMQUA_binder-main/images/neotomaUML_as.svg){#fig-neostructure}

How the above points relate to eachother is illustrated in  (@fig-neostructure).  (@fig-neostructure) is a handy reference for what functions apply to different parts of the workflow. Let’s begin by loading the neotoma package into RStudio.

```{r, message=FALSE, warning=FALSE, results=FALSE}
library(neotoma2)
```

## Finding sites: `get_sites()`

We’ll start with the function `get_sites()`. `get_sites()` returns a `sites` object with metadata about sites. You can use this to find the spatial coverage of data in a region (using `get_sites()` with a bounding box), or to get explicit site information easily from more complex data objects. Use `?get_sites` to see all the options available. `get_site()` is essentially an R wrapper for the API sites and has very similar functionality.

You can easily search by site name, for example.
```{r, message=FALSE, warning=FALSE, results=FALSE}
samwell_site <- get_sites(sitename = 'Samwell%')
print(samwell_site)
```

`get_sites()` can return one site (as above) or many, e.g.:

```{r, message=FALSE, warning=FALSE, results=FALSE}
devil_sites <- get_sites(sitename = 'devil%')
```

`get_sites()` (and most `neotoma2` functions) returns an data object of class `site`, this also allows us to use some of the other `neotoma2` functions more easily. In RStudio, use the Environment panel in upper right to explore the contents of `samwell_site`.


:::{.callout-caution}
## Exercise Question X
How many sites have the name ‘clear’ in them? Show both your code and provide the total count.
:::

You can also search by lat/lon bounding box. This one roughly corresponds to Florida.
__??? Need to update bounding box ???__

```{r, message=FALSE, warning=FALSE, results=FALSE}
FL_sites <- get_sites(loc = c(-88, -79, 25, 30))
```


___??? Geopolitical unites not working for me in neotoma2 ???__
__You can also search by geopolitical name or geopolitical IDs (gpid) stored in Neotoma. For a list of names and gpids, use the get_table(table.name = "GeoPoliticalUnits") command. This command works either with an explicit numeric ID, or with a text string:__

__Example: get all sites in New Mexico (gpid=7956)__

__NM_sites <- get_site(gpid = 7956)__

__get all sites in Wisconsin__

__`WI_sites <- get_site(gpid = “Wisconsin”)``__

__Exercise Question 3 Which state has more sites, Minnesota or Wisconsin? How many of each? Provide both code and answer.__


## Getting datasets: `get_datasets()`

To return the metadata on what datasets a collectionunit has, we use the `get_datasets()` function. `get_datasets()` receives as inputs vectors of site names, vectors of site IDs, or data objects of class site (i.e. output from get_site!). For example:

```{r, message=FALSE, warning=FALSE, results=FALSE}
# We can pass output from get_site to get_datasets:

samwell_datasets <- get_datasets(samwell_site)

print(samwell_datasets)

# Even if get_sites returns multiple sites:

devil.meta.dataset  <- get_datasets(devil_sites)

# Let’s look at the dataset metadata:

devil.meta.dataset
```

:::{.callout-caution}
## Exercise Question X
How many different kinds of datasets are available at Devil’s Lake, WI? Show both code and answer. Ensure that your code just retrieves datasets for just this single site.
:::

## What have I found `browse`

__Sometimes, it’s helpful to quickly spot-check your results using Neotoma Explorer and its quick-look visualizations. You can pass your results back to Explorer using the browse command. browse will accept a numberic value (a single Dataset ID) and data objects of type ‘dataset’, ‘dataset_list’, ‘download’, or ‘download_list’__

__For example: browse(samwell_datasets)__

__Note that browse returns a local result of null to R (which is normal) and then calls a new browser window, showing the Samwell datasets in Neotoma Explorer.__


__REPLACE BROWSE WITH `plotLeaflet()`?__

Sometimes, it’s helpful to quickly spot-check your results using Neotoma Explorer and its quick-look visualizations. You can easily visualise your results using the `plotLeaflet()` function. Mapping results can be especially handy if you have returned a site in an unexpected location when searching for sites by a partial name match. Have a look at the geographical locations of sites returned with the name 'Devil'.

```{r}
plotLeaflet(devil_sites)
```

## Want to read more? `get_publications()`

You can use `get_publications()` to get information on publications associated with sites. Pass in the publication IDs or a dataset object, e.g.: 
```{r, eval=FALSE}
samwell_pubs <- get_publications(samwell_datasets)
# Error in switch(use, dev = "https://api-dev.neotomadb.org/v2.0/", neotoma = "https://api.neotomadb.org/v2.0/",  : 
# EXPR must be a length 1 vector
```


## Downloading data `get_downloads()`

`get_downloads()` returns a list of download objects, one for each retrieved dataset. Note that `get_downloads()` returns the actual data associated with each dataset, rather than a list of the available datasets, as in `get_datasets()` above. `get_downloads()` will accept an object of `class` dataset (e.g., `samwell_dataset`) or of `class` site (e.g., `samwell_site`). If the latter, it will automatically query for the datasets associated in each site. For example:

```{r, message=FALSE, warning=FALSE, results=FALSE}
samwell_datasets_downloads <- get_downloads(samwell_datasets)

samwell_site_downloads <- get_downloads(samwell_site)

print(samwell_datasets_downloads)

print(samwell_site_downloads)
```

Note that by default, `get_downloads()` produces a number of messages. These can be suppressed with the argument `verbose = FALSE` in the function call (`samwell_site_downloads <- get_downloads(samwell_site, verbose = FALSE`).


__Note that not all of the datasets can be downloaded directly to a `download` object. This is because geochronological datasets have a different data structure than other data, requiring different fields, and as such, they are obtained using _???`chronologies()` chronologies only works on a download oblect now? Not a site object?  ???_:__

```{r, message=FALSE, warning=FALSE, results=FALSE}
samwell_geochron <- chronologies(samwell_site_downloads)

print(samwell_geochron)
```

## Filtering: `filter()`

__??? Should Filtering come before downloading???__

Collection units contain datasets (@fig-neostructure). We can use the `datasets()` function on a site (or sites) to return details on what records they contain:

```{r}
datasets(samwell_datasets)
```

Notice that there are seven datasets associated with the `samwell_datasets` object, each one with a `datasetid`. Note that at this point we have not downloaded any data, we are browsing the metadata associated with the site. Downloading data can have a lot of overhead (e.g., download time and API requests), so we try filter results to what we need _before_ downloading the data. For example, if we want to filter the `samwell_datasets` object for vertebrate fauna we can use:

```{r, message=FALSE, warning=FALSE, results=FALSE}
samwell_datasets_vf <- samwell_datasets %>%
  neotoma2::filter(datasettype == "vertebrate fauna" & !is.na(age_range_young))
```

Now, we can use `get_downloads()` to download a single dataset, rather that _all_ the data as we did above. Let's download only the vertebrate datasets for Samwell Cave Popcorn Dome (dataset 14262):

```{r, message=FALSE, warning=FALSE, results=FALSE}
samwell_pd <- get_downloads(14262)
```

## Returning samples

Let’s examine the available data in this download:

## Extracting Taxa

__??? Seems to have changed a lot since `neotoma` no longer `compile_taxa()`???__

## Visualising and analyzing results

__???Should this still follow `analogue` like the older resource or `rijoa` like https://open.neotomadb.org/EPD_binder/simple_workflow.html#Searching_for_datasets: ???__

### Visualising and analyzing a single site

### Visualising and analyzing multiple sites


## Fun with For-Loops

__??? Section still necessary???__