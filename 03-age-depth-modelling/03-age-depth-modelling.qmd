---
title: "Lab 3: Age-depth modelling"
author: "Quinn Asena and Jack Williams"
date: "August 8, 2022"
format:
  html:
    code-fold: false
    toc: true
    link-external-newwindow: true
theme:
  light: flatly
  dark: darkly
---

# Before the lab

__Using what you learned from the last lab:__

1. create a directory for this lab called 03-age-depth-modelling and two sub-directories within it called 'data', and 'outputs'

2. create an R project inside 03-age-depth-modelling, open a new R script, install the packages 'clam', and 'Bchron', and save your script

__Read these two papers:__

1. Bronk Ramsey, C. (2008) Radiocarbon dating: Revolutions in understanding. Archaeometry 50:249-275. Read only to p.260. A good overview of radiocarbon fundamentals and interpretation for a general audience.

2. Blaauw, M. (2010) Methods and code for ‘classical’ age-modelling of radiocarbon sequences. Quaternary Geochronology 5:512-518. Good overview and code for ‘classic’ age-depth modeling: linear interpolation, regression, polynomial regression, splines, etc.

```{r packages, eval=FALSE, include=FALSE}
install.packages("clam")

library(clam)
```

# Part 1: Background
## Introduction
A foundational difference between geology and ecology is that, for geologists, time is an unknown variable that must be estimated with uncertainty. In contrast, most ecologists can assume that the temporal coordinates of their observations are known precisely, with zero uncertainty. Fortunately, geochronologists have a wide variety of natural clocks, thanks to the constant decay rates of radioactive isotopes. Each isotope has a unique decay rate, and so each is appropriate for particular timescales.

For the last 50,000 years, radiocarbon (14C), with its half-life of 5730 years, is by far the most common form of radiometric dating. (Beyond 10 half-lives, so much of a radioactive substance has decayed away that it becomes immeasurable.) Radiocarbon is the mainstay of Quaternary dating and archaeology.

In Quaternary paleoecology, radiocarbon dating is expensive – a single sample typically costs $300 to $500 – so usually a given lake-sediment record will have only a scattering (ca. 5-30) of radiocarbon dates and other age controls. Other kinds of age controls include volcanic ash layers (tephras), 210Pb, optically stimulated luminescence (OSL) dates, historic events such as the rise in Ambrosia pollen abundances associated with EuroAmerican land clearance, etc.) An age model must be constructed to estimate the age of sediments not directly associated with an age control. In multi-site data syntheses, the number of age controls, their precision, and their likely accuracy are all fundamental indicators of data quality (e.g. [Blois et al. 2011](https://www.sciencedirect.com/science/article/pii/S0277379111001193)).

To estimate ages for depths lacking radiocarbon date, an age-depth model is required. Age-depth models are fitted to the available age controls (age estimates with uncertainty for individual depths) and provide estimates of age as a function of depth, for all depths and ages within the temporal bounds of the model.

Here we will gain practice in working with age-depth models of various kinds, using several standard R packages (clam, rbacon, and see also Bchron), and assessing their age estimates and uncertainty. We’ll begin with a bit of practice in calibrating radiocarbon years to calendar years and comparing the calibration estimates from different calibration curves.

## Calibration of Radiocarbon Dates
A complication in radiocarbon dating is that the initial calculation of a radiocarbon age assumes, by convention, that the amount of radiocarbon in the atmosphere is constant over time. See (Bronk Ramsey 2008) for a good overview of 14C dating. This assumption is untrue, so all radiocarbon age estimates must be calibrated using a calibration curve that is based on compiling radiocarbon dates of materials that have precise independent age estimates (e.g. tree rings, corals). The IntCal series (IntCal04, IntCal09, IntCal13, IntCal20) is the community standard for calibrating radiocarbon dates to age estimates in calendar years. The conversion from radiocarbon to calendar years usually further increases the uncertainty of age estimates.

Yet another complication in radiocarbon dating is that different calibration curves need to be used for the Northern vs. Southern Hemisphere and for the atmosphere vs. oceans, due to different residence times of 14C in these different reservoirs. For example, atmospheric radiocarbon that diffuses into the surface oceans usually will reside for centuries before phytoplankton biologically fix it through photosynthesis, which will lead the marine 14C to be depleted (and ‘too old’) relative to atmospheric 14C. Use the wrong calibration curve and your age estimate will be inaccurate!

## Types of Age-Depth Models
Different kinds of age-depth models exist, each with their own underlying assumptions and behavior. In the list below, #1-4 are classical or traditional forms of age-depth models, but Bayesian models (bacon, bchron) are now the norm. For learning purposes, we’ll begin with the classics.

1. **Linear interpolation**, a.k.a. ‘connect the dots,’ in which straight lines are drawn between each depth-adjacent pair of age controls.

2. **Linear regression** ($y=b0 + b1x$; $y=$time and $x=$depth; $b0$ and $b1$ are constants), in which a single straight line is fitted through the entire set of age controls. In ordinary linear regression (OLS), the chosen line will minimize the y-dimension distances of individual points to the line. Standard OLS assumes that all observations are normally distributed, which is a poor assumption for calibrated radiocarbon dates.

3. **Polynomials**, also fitted to the entire set of age controls ($y= b0 + b1x + b2x^2 + b3x^3 + …bnx^n$) and are an extension of linear regression, with additional terms for $x^2$, $x^3$, etc. Some arbitrary maximum n is chosen, usually in the range of 3 to 5.
Splines, which are a special kind of polynomial function that are locally fitted to subsets of the age controls, and then smoothly interpolate between points. (Several different formulas can be used to generate splines; common forms include cubic, smooth, monotonic, and LOWESS).

4. **Bayesian age models** (e.g. bacon, bchron, oxcal, etc.). Bayesian models differ in detail, but all combine a statistical representation of prior knowledge with the new data (i.e. the age controls at a site) to build an age-depth model with posterior estimates of age for any given depth. Bayesian models are now widely used because 1) they allow the incorporation of prior knowledge (e.g., from coring many lakes, we now have decent estimates of typical sediment accumulation rates, (Goring et al. 2012); 2) they can handle highly irregular probability distribution functions such as those for after-calibration radiocarbon dates; and as a result 3) they generally do a better job of describing uncertainty than traditional age-depth models.

# Part 2: Exercises


## Callibration

 Radiocarbon dates need to be calibrated to place them on the calendar year scale. Different calibration curves are used for the Northern and Southern Hemispheres, and sediment types. The package `Bchron` makes calibrating dates to different curves easy for us.

:::{.callout-note}
## Note
Recall from the previous lab that you need to load packages with the `library()` function before you can access the functions provided by `Bchron`. Alternatively you can use the syntax `package::function()` to specify a function from a particular package. For example, `Bchron::BchronCalibrate()`.
:::

First, we will check out different calibration curves of a single date using the example provided in the `Bchron` help. The function for calibrating radiocarbon dates in `Bchron` is `BchronCalibrate()`.

:::{.callout-caution}
## Ecercise

1. using the help `?`, read the documentation of the `BchronCalibrate` function and run the first example provided.

    - You can copy and paste the code into your R script.

2. run the same example using a different inputs for `calCurves = ` argument. Try using both the Shouthern Hemisphere curve and the marine curves.
:::

:::{.callout-warning}
## Homework
Construct a table of a single date calibrated to three different curves specifying:

- the calibration curve used.

- the original radiocarbon age and standard deviation.

- the calibrated age ranges from `summary()`.
:::

## Classical age-depth

'Classical' age-depth modelling was used prior to recent developments in advanced statistical methods for fitting age-depth models. We will explore and compare the results from some classical models using the `clam` package. The authors of the `clam` package have developed a more advanced package (`rbacon`, referred to as 'bacon') for age-depth modelling and `clam` is now out of date. However, it is useful to see how different classical models work as, prior to the development of Bayesian methods, they were used and are reported in the literature.


:::{.callout-caution}
## Exercise

1. I have posted a sample geochronology dataset (clam_runs/DevilsLakeAMS/DevilsLakeAMS.csv) from Devils Lake WI to give an example of the input directory structure and file formatting expected by clam.

    i) download the directory (clam_runs) to your current working directory (03-age-depth-modelling)

    ii) clam expects input dates in a csv file in a sub-directory of the same name (e.g. clam_runs/MyCore1/MyCore1.csv)

    iii) the function you need to run the model is `clam()`. Use the help `?` to understand the arguments of the function

2. Build the following age-depth models

    i) linear interpolation (`type=1`)

    ii) linear regression (`type=2) [default is linear`]

    iii) 3rd-order polynomial (`type=2, smooth=3`) [the smooth parameter sets the polynomial degree]

    iv) cubic spline (`type=3`)

Note that `clam` will save outputs to the directory clam_runs/DevilsLakeAMS/DevilsLakeAMS.csv, including the age depth model plots you need for the homework below. Newer package generate the plots and data that can be storred as objects in R (this way is better!).
:::


:::{.callout-warning}
## Homework

- Add the classical age-depth from clam to your homework. One axis should show depth and the other show age. Make sure each plot is titled so that I know which model is which.

- Look at the Devils Lake pollen diagram in Neotoma Explorer and pick two notable vegetation events (e.g. end-Pleistocene Picea decline). Then, identify the depths of these events in Neotoma Explorer and use your output from clam to build a table that reports the inferred mean age and 95% CI of these events in separate columns. Your table will have at least the columns: depth,	min95%,	max95%,	best, accrate.

- Using clam, construct a cubic spline (`type=3`) with the default smoothing parameter

- Experiment with alternative values of the smooth parameter and pick 3-4 that show a range of model behavior

- Homework: As in 3., make age-depth plots to show the various splines. To the table created above, add columns that reports the mean age estimates and uncertainties.
Note that in clam you can also specify the position of ‘slumps’ (instantaneously deposited sediments, like a flood layer) and ‘hiatuses’ (gaps in the sediment record). Feel free to play with these options.
:::


## Exercise 3: Bayesian age-depth modelling

There are two equally advanced package for age-depth modelling in R: `rbacon` (usually called just bacon) and `Bchron`. We will be experimenting with `Bchron` as it is marginally more user friendly in R. Bacon requires a specific directory structure and column ordering of data. Remember, software such as R and packages such as Bacon regularly update. Things that were difficult or impossible last month may have changed by the next.

Bchron has a useful [guide](https://cran.r-project.org/web/packages/Bchron/vignettes/Bchron.html#calibrating-radiocarbon-dates) with a working example using a dataset built-in with the package. Today we will use the Devil's Lake data. Download the csv file: 'devils_lake_bchron.csv' to your working directory, and read it into R as a data.frame. Check out the structure of the data. Unlike `rbacon`, in `Bchron` the data do not need to be stored in a specific directory structure and the columns do not need to be in a specific order. 

:::{.callout-warning}
## Homework

__Download the Devil's Lake data from the bchron_data directory.__ The data are the same, only the structure is slightly modified to work with `Bchron`. Using the `Bchron` guide:

1. Find the working example of how to run the age depth model and adapt the code to run the model on the Devil's lake data

2. Include the `plot` output from the age depth model of Devil's Lake to your homework

3. Include the `summary` output as a table in your homework
:::